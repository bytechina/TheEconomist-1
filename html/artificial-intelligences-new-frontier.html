<html lang="en"><meta name="viewport" content="width=device-width, initial-scale=1" /><head><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-2VYEP6CXDE"></script><script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag("js", new Date());  gtag("config", "G-2VYEP6CXDE");</script><link rel="stylesheet" href="../init.css"></head><body><section class="css-ps9sjo e1q9n20l0"><div class="css-nxgt9g e1wpftot0"><span class="css-1pipetz e1mwh2nm0"><a data-analytics="sidebar:section" href="/leaders/">Leaders</a></span><span class="css-1wi1zzr e1kwye4o0"> | <!-- -->Foundation models</span></div><h1 class="css-1bo5zl0 eoacr0f0">Artificial intelligence’s new frontier</h1><h2 class="css-4vhs4z ecgqxun0">The promise and perils of a breakthrough in machine intelligence</h2></section><img id="myImg" src="../image/20220611_LDD002.jpg" width="auto" height="200"><div class="css-1osicwh e15vdjh41"><p class="article__body-text article__body-text--dropcap" data-caps="initial"><span data-caps="initial">P</span><small>icture a computer </small>that could finish your sentences, using a better turn of phrase; or use a snatch of melody to <a href="./composing-by-computer.html">compose music</a> that sounds as if you wrote it (though you never would have); or solve a problem by creating hundreds of lines of computer code—leaving you to focus on something even harder. In a sense, that computer is merely the descendant of the power looms and steam engines that hastened the Industrial Revolution. But it also belongs to a new class of machine, because it grasps the symbols in language, music and programming and uses them in ways that seem creative. A bit like a human. </p><p class="article__body-text">The “<a href="https://econ.st/3xCZiif">foundation models</a>” that can do these things represent a breakthrough in artificial intelligence, or <small>ai</small>. They, too, promise a revolution, but this one will affect the high-status brainwork that the Industrial Revolution never touched. There are no guarantees about what lies ahead—after all, <small>ai</small> has stumbled in the past. But it is time to look at the promise and perils of the next big thing in machine intelligence.</p><div class="advert incontent hidden advert--inline"><div><div class="adcontainer" id="econ-1"></div></div></div><p class="article__body-text">Foundation models are the latest twist on “<a href="./how-machine-learning-works.html">deep learning</a>” (<small>dl</small>), a technique that rose to prominence ten years ago and now dominates the field of <small>ai</small>. Loosely based on the networked structure of neurons in the human brain, <small>dl</small> systems are “trained” using millions or billions of examples of texts, images or sound clips. In recent years the ballooning cost, in time and money, of training ever-larger <small>dl</small> systems had prompted worries that the technique was reaching its limits. Some fretted about an “<small>ai</small> winter”. But foundation models show that building ever-larger and more complex <small>dl</small> does indeed continue to unlock ever more impressive new capabilities. Nobody knows where the limit lies.</p><p class="article__body-text">The resulting models are a new form of creative, non-human intelligence. The systems are sophisticated enough both to possess a grasp of language and also to break the rules coherently. A dog cannot laugh at a joke in the <i>New Yorker</i>, but an <small>ai</small> can explain why it is funny—a feat that is, frankly, sometimes beyond readers of the <i>New Yorker</i>. When we asked one of these models to create a collage using the title of this leader and nothing more, it came up with the cover art for our American and Asian editions, pictured (we tried to distract our anxious human designers with a <a href="./low-economic-growth-is-a-slow-burning-crisis-for-britain.html">different cover</a> in our European editions). </p><p class="article__body-text">Foundation models have some surprising and useful properties. The eeriest of these is their “emergent” behaviour—that is, skills (such as the ability to get a joke or match a situation and a proverb) which arise from the size and depth of the models, rather than being the result of deliberate design. Just as a rapid succession of still photographs gives the sensation of movement, so trillions of binary computational decisions fuse into a simulacrum of fluid human comprehension and creativity that, whatever the philosophers may say, looks a lot like the real thing. Even the creators of these systems are surprised at their power. </p><div class="advert incontent hidden advert--inline"><div><div class="adcontainer" id="econ-2"></div></div></div><p class="article__body-text">This intelligence is broad and adaptable. True, foundation models are capable of behaving like an idiot, but then humans are, too. If you ask one who won the Nobel prize for physics in 1625, it may suggest Galileo, Bacon or Kepler, not understanding that the first prize was awarded in 1901. However, they are also adaptable in ways that earlier <small>ai</small>s were not, perhaps because at some level there is a similarity between the rules for manipulating symbols in disciplines as different as drawing, creative writing and computer programming. This breadth means that foundation models could be used in lots of applications, from helping find new drugs using predictions about how proteins fold in three dimensions, to selecting interesting charts from datasets and dealing with open-ended questions by trawling huge databases to formulate answers that open up new areas of inquiry. </p><p class="article__body-text">That is exciting, and promises to bring <a href="./foundational-AI-pod.html">great benefits</a>, most of which still have to be imagined. But it also stirs up worries. Inevitably, people fear that <small>ai</small>s creative enough to surprise their creators could become malign. In fact, foundation models are light-years from the sentient killer-robots beloved by Hollywood. Terminators tend to be focused, obsessive and blind to the broader consequences of their actions. Foundational <small>ai</small>, by contrast, is fuzzy. Similarly, people are anxious about the prodigious amounts of power training these models consume and the emissions they produce. However, <small>ai</small>s are becoming more efficient, and their insights may well be essential in developing the technology that accelerates a shift to renewable energy. </p><p class="article__body-text">A more penetrating worry is over who controls foundation models. Training a really large system such as Google’s <small>P</small>a<small>LM </small>costs more than $10m a go and requires access to huge amounts of data—the more computing power and the more data the better. This raises the spectre of a technology concentrated in the hands of a small number of tech companies or governments.</p><p class="article__body-text">If so, the training data could further entrench the world’s biases—and in a particularly stifling and unpleasant way. Would you trust a ten-year-old whose entire sense of reality had been formed by surfing the internet? Might Chinese- and American-trained <small>ai</small>s be recruited to an ideological struggle to bend minds? What will happen to cultures that are poorly represented online?</p><p class="article__body-text">And then there is the question of access. For the moment, the biggest models are restricted, to prevent them from being used for nefarious purposes such as generating fake news stories. Open<small>ai, </small>a startup, has designed its model, called <small>DALL-E</small> 2, in an attempt to stop it producing violent or pornographic images. Firms are right to fear abuse, but the more powerful these models are, the more limiting access to them creates a new elite. Self-regulation is unlikely to resolve the dilemma.</p><h2>Bring on the revolution</h2><p class="article__body-text">For years it has been said that <small>ai</small>-powered automation poses a threat to people in repetitive, routine jobs, and that artists, writers and programmers were safer. Foundation models challenge that assumption. But they also show how <small>ai</small> can be used as a software sidekick to enhance productivity. This machine intelligence does not resemble the human kind, but offers something entirely different. Handled well, it is more likely to complement humanity than usurp it. <span data-ornament="ufinish">■</span></p><p class="article__body-text"><i>For subscribers only: to see how we design each week’s cover, sign up to our weekly <a href="./page-not-found.html">Cover Story newsletter</a>.</i></p></div></body></html>