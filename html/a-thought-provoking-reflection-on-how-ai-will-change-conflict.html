<html lang="en"><meta name="viewport" content="width=device-width, initial-scale=1" /><head><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-2VYEP6CXDE"></script><script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag("js", new Date());  gtag("config", "G-2VYEP6CXDE");</script><link rel="stylesheet" href="../init.css"><title>A thought-provoking reflection on how AI will change conflict</title></head><body><div class="ds-layout-grid ds-layout-grid--edged layout-article-header"><script type="application/ld+json">
{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https://www.economist.com/books-and-arts/","name":"Books & arts"}},{"@type":"ListItem","position":2,"item":{"@id":"https://www.economist.com/printedition/2021-07-03","name":"Jul 3rd 2021 edition"}}]}
</script><div class="article__section"><strong itemprop="articleSection"><span class="article__section-headline"><a href="/books-and-arts/">Books &amp; arts</a></span></strong><a class="article__section-edition" data-test-id="Article Datetime" href="/printedition/2021-07-03"><span>Jul 3rd 2021<!-- --> edition</span></a></div><header class="article__header"><h1><span class="article__subheadline" data-test-id="Article Subheadline">The future of war</span><br/><span class="article__headline" data-test-id="Article Headline" itemprop="headline">A thought-provoking reflection on how AI will change conflict</span></h1><h2 class="article__description" data-test-id="Article Description" itemprop="description">Algorithms may make proficient soldiers but poor generals</h2></header><div class="article__lead-image" data-test-id="Lead Image"><div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject"><meta content="https://www.economist.com/img/b/1280/720/90/sites/default/files/images/2021/06/articles/main/20210703_bkp503.jpg" itemprop="url"/><img alt="" height="720" sizes="(min-width: 1440px) 940px, (min-width: 1080px) 75vw, (min-width: 960px) 90vw, (min-width: 800px) 720px, 95vw" src="../image/20210703_bkp503.jpg" srcset="../image/20210703_bkp503.jpg" width="1280"/></div></div><hr class="ds-rule layout-article-header__rule"/><div class="advert right hidden advert--right-rail" id=""><div><div class="adcontainer" id="econright-r0"></div></div></div></div><div class="ds-layout-grid ds-layout-grid--edged layout-article-body" itemprop="text"><div class="layout-sticky-rail"><div class="layout-sticky-rail-advert-wrapper"><div class="advert right hidden advert--right-rail advert--sticky-rail" id=""><div><div class="adcontainer" id="econright-r1"></div></div></div></div></div><p class="article__body-text"><strong>I, Warbot. </strong>By Kenneth Payne. <em>Oxford University Press; 336 pages; $29.95. Hurst; £20</em></p><p class="article__body-text article__body-text--dropcap" data-caps="initial"><span data-caps="initial">T</span><small>HE UN’S</small> Panel of Experts on Libya rarely grabs the headlines. But its valedictory report in March caused a furore. It noted that in a battle around Tripoli last year, Libya’s government had “hunted down and remotely engaged” the enemy with drones—and not just any drones. The Kargu-2 was programmed to attack “without requiring data connectivity between the operator and the munition”. The implication was that it could pick its own targets.</p><div class="article-audio-player"><figure class="article-audio-player__figure"><figcaption>Listen to this story</figcaption><audio class="react-audio-player" controls="" controlslist="nodownload" id="audio-player" preload="none" src="../audio/a-thought-provoking-reflection-on-how-ai-will-change-conflict.mp3" title="A thought-provoking reflection on how AI will change conflict"><p>Your browser does not support the &lt;audio&gt; element.</p></audio></figure><p class="article-audio-player__cta">Enjoy more audio and podcasts on<!-- --> <a href="https://apps.apple.com/app/apple-store/id1239397626?pt=344884&amp;ct=article%20audio%20player&amp;mt=8" id="audio-ios-cta" rel="noreferrer" target="_blank">iOS</a> <!-- -->or<!-- --> <a href="https://play.google.com/store/apps/details?id=com.economist.lamarr&amp;referrer=utm_source%3Darticle%2520audio%2520player" id="audio-android-cta" rel="noreferrer" target="_blank">Android</a>.</p></div><p class="article__body-text">Was this a true autonomous weapon, or just a clever missile? In June the Turkish manufacturer insisted that, contrary to its own marketing, for now the drone required a human to push the button. This sort of technology is at the heart of “I, Warbot” by Kenneth Payne, a thought-provoking reflection on how artificial intelligence (<small>AI</small>) will change conflict.</p><p class="article__body-text">In some ways, the story is familiar. It involves the entwined histories of computing and warfare; the recent evolution of new, powerful forms of <small>AI</small> modelled on the neurons of the brain rather than the logic of the mind; and the ensuing possibilities for weapons to see what is around them—and strike with superhuman speed and precision. Mr Payne, an academic at King’s College London, is especially bullish on the potential of swarms, “a menagerie of specialist robots” that can concentrate to attack and melt away just as quickly.</p><div class="advert incontent hidden advert--inline" id=""><div><div class="adcontainer" id="econ-1"></div></div></div><p class="article__body-text">“The tactical implications are profound,” he predicts. The offence will dominate. Defenders will have to rely on deception, generating clouds of decoy targets, rather than on protections like armour and fortification. Martial virtues such as courage and leadership will give way to technical competence. Dividing armed forces into services optimised for land, air and sea may look increasingly strange in a world of machines that can range across them.</p><p class="article__body-text">Above all, though, “I, Warbot” is a reminder that war is about more than tactics. It is about choosing which battles to fight, how to knit them into a successful campaign and how to connect military victories to political aims—in short, war is about strategy. And soldiery and strategy are fundamentally different. Computer programs can already defeat human pilots in simulated dogfights. But could they come up with the bold, swift and visionary attacks that let Napoleon Bonaparte knock out one European army after another?</p><p class="article__body-text">Algorithms can certainly outwit opponents in games that blend skill, chance and psychology. In 2017 Libratus, a computer program, saw off four poker stars. <small>AI</small> can also innovate: in 2016 AlphaGo, another program, thrashed a world champion of Go, an ancient Chinese board-game, with moves that dazzled onlookers.</p><p class="article__body-text">But, argues Mr Payne, this is a simulacrum of genius, not the real thing. These gizmos exhibit “exploratory creativity”—essentially a brute-force calculation of probabilities. That is fundamentally different from “transformational creativity”, which entails the ability to consider a problem in a wholly new way, and requires playfulness, imagination and a sense of meaning. All that may depend on emotion, and thus on parts of human biology alien to computers. “<small>AI</small> is a statistical processor par excellence”; but in essence it remains “a wonderfully sophisticated abacus”.</p><div class="advert incontent hidden advert--inline" id=""><div><div class="adcontainer" id="econ-2"></div></div></div><p class="article__body-text">A proficient soldier, the warbot may thus be a limited general. The problem is that the line between tactics and strategy can blur. Battlefield decisions can have geopolitical ramifications. Consider the case of B-59, a Soviet submarine pounded by American depth-charges during the Cuban missile crisis of 1962. The frazzled captain ordered the use of a nuclear-tipped torpedo. Conscious of the stakes, Vasily Arkhipov, the second-in-command, refused to authorise the launch.</p><p class="article__body-text">Would a computer have done so? “A warbot is likely to be more accurate, proportionate and discriminate” than humans, says Mr Payne. The risk is that “a machine is undeterred by the sobering fear of things getting out of hand.” <span data-ornament="ufinish">■</span></p><p class="article__footnote" data-test-id="Footnote">This article appeared in the Books &amp; arts section of the print edition under the headline "Computer says go"</p><div class="layout-article-links layout-article-promo"><a class="ds-actioned-link ds-actioned-link--reuse-this-content" href="https://s100.copyright.com/AppDispatchServlet?publisherName=economist&amp;publication=economist&amp;title=A%20thought-provoking%20reflection%20on%20how%20AI%20will%20change%20conflict&amp;publicationDate=2021-07-01&amp;contentID=%2Fcontent%2F0sjpfrle2i42n9a8rkbs945up7jsat2i&amp;type=A&amp;orderBeanReset=TRUE" target="_blank"><span>Reuse this content</span></a><a class="ds-actioned-link ds-actioned-link--the-trust-project" href="https://www.economist.com/frequently-asked-questions"><span>The Trust Project</span></a></div></div></body></html>