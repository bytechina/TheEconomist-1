<html lang="en"><meta name="viewport" content="width=device-width, initial-scale=1" /><head><link rel="stylesheet" href="../init.css"><title>Composing by computer</title></head><body><div class="ds-layout-grid ds-layout-grid--edged layout-article-header"><div class="article__lead-image" data-test-id="Lead Image"><div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject"><meta content="https://www.economist.com/img/b/1280/720/90/sites/default/files/images/2021/06/articles/main/20210605_stp002.jpg" itemprop="url"/><img alt="" height="720" sizes="(min-width: 1440px) 940px, (min-width: 1080px) 75vw, (min-width: 960px) 90vw, (min-width: 800px) 720px, 95vw" src="../image/20210605_stp002.jpg" srcset="../image/20210605_stp002.jpg" width="1280"/></div></div><header class="article__header"><h1><span class="article__subheadline" data-test-id="Article Subheadline">Programmes by programs</span><br/><span class="article__headline" data-test-id="Article Headline" itemprop="headline">Composing by computer</span></h1><h2 class="article__description" data-test-id="Article Description" itemprop="description">Concerts may soon feature music written by artificial intelligence</h2></header><script type="application/ld+json">
{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https://www.economist.com/science-and-technology/","name":"Science & technology"}},{"@type":"ListItem","position":2,"item":{"@id":"https://www.economist.com/printedition/2021-06-05","name":"Jun 5th 2021 edition"}}]}
</script><div class="article__section"><strong itemprop="articleSection"><span class="article__section-headline"><a href="/science-and-technology/">Science &amp; technology</a></span></strong><a class="article__section-edition" data-test-id="Article Datetime" href="/printedition/2021-06-05"><span>Jun 5th 2021<!-- --> edition</span></a></div><hr class="ds-rule layout-article-header__rule"/><div class="advert right hidden advert--right-rail" id=""><div><div id="econright-r0"></div></div></div></div><div class="ds-layout-grid ds-layout-grid--edged layout-article-body" itemprop="text"><div class="layout-sticky-rail"><div class="layout-sticky-rail-advert-wrapper"><div class="advert right hidden advert--right-rail advert--sticky-rail" id=""><div><div id="econright-r1"></div></div></div></div></div><p class="article__body-text article__body-text--dropcap" data-caps="initial"><span data-caps="initial">T</span><small>HESE DAYS</small>, anyone with a computer can be a composer. Sort of. Give a piece of commercial software such as Magenta, developed by Google, the first few notes of a song, and it will make something merrily tuneful out of them. Tuneful, but not sophisticated. At least, that is the view of Gerhard Widmer of Johannes Kepler University, in Linz, Austria.</p><div class="article-audio-player"><figure class="article-audio-player__figure"><figcaption>Listen to this story</figcaption><audio class="react-audio-player" controls="" controlslist="nodownload" id="audio-player" preload="none" src="https://www.economist.com/media-assets/audio/085%20Science%20and%20technology%20-%20Composing%20by%20computer-9b9a2aadd79062b7ee19c020b50ea6f5.mp3" title="Composing by computer"><p>Your browser does not support the &lt;audio&gt; element.</p></audio></figure><p class="article-audio-player__cta">Enjoy more audio and podcasts on<!-- --> <a href="https://apps.apple.com/app/apple-store/id1239397626?pt=344884&amp;ct=article%20audio%20player&amp;mt=8" id="audio-ios-cta" rel="noreferrer" target="_blank">iOS</a> <!-- -->or<!-- --> <a href="https://play.google.com/store/apps/details?id=com.economist.lamarr&amp;referrer=utm_source%3Darticle%2520audio%2520player" id="audio-android-cta" rel="noreferrer" target="_blank">Android</a>.</p></div><p class="article__body-text">In Dr Widmer’s opinion, “what they create may contain certain statistical properties. It’s not dissonant, but it’s not actually music...It would create a piece that would last three days because it has no notion of what it wants to do. It doesn’t know that things need an end, a beginning, and something in-between.” He thinks he can do better. He wants to use artificial intelligence to explore how toying with a listener’s expectations affects the perception of music, and then to employ that knowledge to create software which can produce something more akin to Beethoven than “Baa Baa Black Sheep”. That means giving computers an ability to perceive subtleties they cannot currently detect but might, using the latest techniques, be able to learn. To this end, Dr Widmer is running a project called “Whither music?”—a title borrowed from a lecture series given at Harvard University in 1973 by <a href="/books-and-arts/2018/01/18/leonard-bernstein-at-100">Leonard Bernstein</a>, a celebrated 20th-century composer.</p><div class="advert incontent hidden advert--inline" id=""><div><div id="econ-1"></div></div></div><p class="article__body-text">When human beings listen to music, they subconsciously predict what the next note will be. One trick composers use is to toy with these expectations—sometimes delivering what is expected and sometimes deliberately taking an unexpected turn. Performers then enhance that emotional manipulation by adding expression—for example, by playing a particular phrase louder or more staccato than the one which came before. One thing Dr Widmer is doing, therefore, is teaching computers to copy them.</p><p class="article__body-text">To this end, he and his colleagues have amassed a huge body of recordings captured on specially designed instruments, notably the Bösendorfer 290 <small>SE</small>, a type of concert piano made in the 1980s which was rigged by the manufacturers with sensors that measure the force and timings of the pianist’s key-pressing with great accuracy. The jewel of their collection is a set of performances on a 290 <small>SE</small> by Nikita Magaloff (pictured), a legendary concert pianist and Chopin expert, of almost all of Chopin’s solo piano work. These were recorded at a series of six concerts which Magaloff gave in Vienna, shortly before his death in 1992.</p><p class="article__body-text">The team’s software takes data from these and other, humbler recordings and compares them with the score as written by the composer. It is looking for mismatches between the two—places, for instance, where the performer misses the beat by a few milliseconds or plays a note more forcefully than the score indicates. By analysing thousands of performances and comparing them with digitised versions of the composers’ scores, the software learns what performers are choosing to accentuate when they play, and thus what those performers think is particularly interesting to the audience.</p><div class="advert incontent hidden advert--inline" id=""><div><div id="econ-2"></div></div></div><p class="article__body-text">Other algorithms are being taught the rules of composition. “[Existing software models] take all the past notes that have already been played and predict the next note, which has nothing to do with how a human composer would compose,” Dr Widmer explains. “Composition is a planning process that involves structure. We want to create models that make predictions at several levels simultaneously.” The team are designing and training individual modules for different elements of music: melody, rhythm, harmony and so on—with the intention of combining them into a master program that can be trained on performances and scores <em>in toto</em>.</p><p class="article__body-text">Once complete, the resulting megabyte maestro will decide not just which note follows which, but why that should be so and how that note should be played. “Instead of saying, ‘the next note is statistically likely to be a C’, it would say, ‘I believe that the next four bars will feature some kind of IV-I-V harmony [a common type of chord progression in Western music], because we had a similar pattern in a similar melodic context earlier in the piece’.”</p><p class="article__body-text">Software of this sort might have applications beyond composition. Existing “<a href="/special-report/2017/02/09/how-to-devise-the-perfect-recommendation-algorithm">recommender</a>” algorithms struggle to generate musical playlists that appeal to particular tastes. A recent paper showed that they are good at suggesting pieces for fans of pop music with catholic appetites, but not for those who prefer a specific genre, such as heavy metal or rap. Software that understands musical expectancy might do a better job. A program which knows what to listen out for might discover that the music of Skepta or Slayer has specific types of musical surprises within it, and, on this basis, be able to recommend new music with similar surprises.</p><p class="article__body-text">Whether computer software will ever be able to write music that stands up to comparison with the likes of Chopin or Cream remains to be seen. Dr Widmer remains sceptical, but it is hard to see why. Great art is often a product of knowing when to obey the rules and when to break them. And that is exactly what he is teaching his machines. <span data-ornament="ufinish">■</span></p><p class="article__body-text"><em>A version of this article was published online on June 2nd 2021</em></p><p class="article__footnote" data-test-id="Footnote">This article appeared in the Science &amp; technology section of the print edition under the headline "Programmes by programs"</p><div class="layout-article-links layout-article-promo"><a class="ds-actioned-link ds-actioned-link--reuse-this-content" href="https://s100.copyright.com/AppDispatchServlet?publisherName=economist&amp;publication=economist&amp;title=Composing%20by%20computer&amp;publicationDate=2021-06-03&amp;contentID=%2Fcontent%2Fgaf40imteifvt49ufqavgr5nf0vnkrp7&amp;type=A&amp;orderBeanReset=TRUE" target="_blank"><span>Reuse this content</span></a><a class="ds-actioned-link ds-actioned-link--the-trust-project" href="https://www.economist.com/about-the-economist"><span>The Trust Project</span></a></div></div></body></html>